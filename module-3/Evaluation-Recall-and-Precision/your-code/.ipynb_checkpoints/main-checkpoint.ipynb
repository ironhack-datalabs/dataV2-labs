{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Precision & Recall\n",
    "## Using the evaluation metrics we have learned, we are going to compare how well some different types of classifiers perform on different evaluation metrics\n",
    "### We are going to use a dataset of written numbers which we can import from sklearn. Run the code below to do so. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784')\n",
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now take a look at the shapes of the X and y matricies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's pick one entry and see what number is written. Use indexing to pick the 36000th digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pixel1      0.0\n",
       "pixel2      0.0\n",
       "pixel3      0.0\n",
       "pixel4      0.0\n",
       "pixel5      0.0\n",
       "           ... \n",
       "pixel780    0.0\n",
       "pixel781    0.0\n",
       "pixel782    0.0\n",
       "pixel783    0.0\n",
       "pixel784    0.0\n",
       "Name: 35999, Length: 784, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[35999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can use the .reshape(28,28) function and plt.imshow() function with the parameters cmap = matplotlib.cm.binary, interpolation=\"nearest\" to make a plot of the number. Be sure to import matplotlib!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "image = np.array(X.iloc[36000]).reshape(28, 28)\n",
    "\n",
    "plt.imshow(image, cmap=matplotlib.cm.binary, interpolation='nearest')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use indexing to see if what the plot shows matches with the outcome of the 36000th index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.iloc[36000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets break into a test train split to run a classification. Instead of using sklearn, use indexing to select the first 60000 entries for the training, and the rest for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:60000]\n",
    "y_train = y[:60000]\n",
    "X_test = X[60000:]\n",
    "y_test = y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        5\n",
       "1        0\n",
       "2        4\n",
       "3        1\n",
       "4        9\n",
       "        ..\n",
       "59995    8\n",
       "59996    3\n",
       "59997    5\n",
       "59998    6\n",
       "59999    8\n",
       "Name: class, Length: 60000, dtype: category\n",
       "Categories (10, object): ['0', '1', '2', '3', ..., '6', '7', '8', '9']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to make a two-class classifier, so lets restrict to just one number, for example 5s. Do this by defining a new y training and y testing sets for just the number 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_training5 = np.where(y_train.astype('int') == 5, 1, 0)\n",
    "y_testing5 = np.where(y_test.astype('int') == 5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_testing5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets train a logistic regression to predict if a number is a 5 or not (remember to use the 'just 5s' y training set!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/osboxes/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_training5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does the classifier predict correctly the 36000th digit we picked before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[36000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_preds = clf.predict(X_train)\n",
    "clf_preds[36000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_test_preds = clf.predict(X_test)\n",
    "clf_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To make some comparisons, we are going to make a very dumb classifier, that never predicts 5s. Build the classifier with the code below, and call it using: never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "\n",
    "never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets fit and predict on the testing set using our never 5 Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "never_5_clf.fit(X_train,y_training5)\n",
    "never_5_preds = never_5_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare this to the Logistic Regression. Examine the confusion matrix, precision, recall, and f1_scores for each. What is the probability cutoff you are using to decide the classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9034   74]\n",
      " [ 147  745]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "cm = metrics.confusion_matrix(y_testing5, clf_test_preds)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9108    0]\n",
      " [ 892    0]]\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(y_testing5, never_5_preds)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9096459096459096\n",
      "0.8352017937219731\n",
      "0.8708357685563999\n",
      "0.9779\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(y_testing5, clf_test_preds)\n",
    "recall = recall_score(y_testing5, clf_test_preds)\n",
    "f1_score = f1_score(y_testing5, clf_test_preds)\n",
    "accuracy = accuracy_score(y_testing5, clf_test_preds)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1_score)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/osboxes/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "precision = precision_score(y_testing5, never_5_preds)\n",
    "recall = recall_score(y_testing5, never_5_preds)\n",
    "f1_score = f1_score(y_testing5, never_5_preds)\n",
    "accuracy = accuracy_score(y_testing5, never_5_preds)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1_score)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the differences you see? Without knowing what each model is, what can these metrics tell you about how well each works?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the first model is working and not the second. The accuracy show our models are efficient, but the second is efficient for nothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's examine the roc_curve for each. Use the roc_curve method from sklearn.metrics to help plot the curve for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now find the roc_auc_score for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does this metric tell you? Which classifier works better with this metric in mind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
