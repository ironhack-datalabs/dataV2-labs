{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Lab\n",
    "\n",
    "You will find in this notebook some scrapy exercises to practise your scraping skills.\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- Check the response status code for each request to ensure you have obtained the intended content.\n",
    "- Print the response text in each request to understand the kind of info you are getting and its format.\n",
    "- Check for patterns in the response text to extract the data/info requested in each question.\n",
    "- Visit the urls below and take a look at their source code through Chrome DevTools. You'll need to identify the html tags, special class names, etc used in the html content you are expected to extract.\n",
    "\n",
    "**Resources**:\n",
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide)\n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [lxml lib](https://lxml.de/)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the libraries and modules you may need. `requests`,  `BeautifulSoup` and `pandas` are already imported for you. If you prefer to use additional libraries feel free to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download, parse (using BeautifulSoup), and print the content from the Trending Developers page from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/developers'\n",
    "html = requests.get(url).content\n",
    "code_source = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the names of the trending developers retrieved in the previous step.\n",
    "\n",
    "Your output should be a Python list of developer names. Each name should not contain any html tag.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Find out the html tag and class names used for the developer names. You can achieve this using Chrome DevTools.\n",
    "\n",
    "1. Use BeautifulSoup to extract all the html elements that contain the developer names.\n",
    "\n",
    "1. Use string manipulation techniques to replace whitespaces and linebreaks (i.e. `\\n`) in the *text* of each html element. Use a list to store the clean names.\n",
    "\n",
    "1. Print the list of names.\n",
    "\n",
    "Your output should look like below:\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_names = code_source.find_all(\"div\", {\"class\":\"position-relative container-lg p-responsive pt-6\"})\n",
    "\n",
    "#boucle\n",
    "\n",
    "#name = developer_names_soup.a.string\n",
    "\n",
    "#for element in developer_names_soup:\n",
    "#    print(developer_names_soup.a.string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FrancoisZaninotto',\n",
       " 'FonsvanderPlas',\n",
       " 'RichHarris',\n",
       " 'StefanoGottardo',\n",
       " 'JesseDuffield',\n",
       " 'HaThach',\n",
       " 'franciscosouza',\n",
       " 'Barryvd.Heuvel',\n",
       " 'JonathanReinink',\n",
       " 'BradFitzpatrick',\n",
       " 'SebastiánRamírez',\n",
       " 'DavidTolnay',\n",
       " 'MladenMacanović',\n",
       " 'GlebBahmutov',\n",
       " 'ArtemZakharchenko',\n",
       " 'MikeMcQuaid',\n",
       " 'OmryYadan',\n",
       " 'MariuszNowak',\n",
       " 'EricLiu',\n",
       " 'MikePenz',\n",
       " 'SteveSmith',\n",
       " 'MartenSeemann',\n",
       " 'JoshBleecherSnyder',\n",
       " 'JacobQuinn',\n",
       " 'HadleyWickham']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = developer_names[0].find_all(\"article\")\n",
    "articles[0].h1.a.string\n",
    "\n",
    "liste = [str(art.h1.a.string).replace(' ','').replace('\\n','') for art in articles if str(art.h1.a.string) != \"None\"]\n",
    "liste\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the trending Python repositories in GitHub.\n",
    "\n",
    "The steps to solve this problem is similar to the previous one except that you need to find out the repository names instead of developer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url2 = 'https://github.com/trending/python?since=daily'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "html2 = requests.get(url2).content\n",
    "code_source_repo = BeautifulSoup(html2, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_names = code_source_repo.find_all(\"div\", {\"class\":\"position-relative container-lg p-responsive pt-6\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['archlinux',\n",
       " 'ytdl-org',\n",
       " 'facebookresearch',\n",
       " 'Rapptz',\n",
       " 'gto76',\n",
       " 'philippnormann',\n",
       " 'fudan-zvg',\n",
       " 'hpyproject',\n",
       " 'beurtschipper',\n",
       " 'projectdiscovery',\n",
       " 'python-telegram-bot',\n",
       " 'matplotlib',\n",
       " 'frappe',\n",
       " 'fireeye',\n",
       " 'CastagnaIT',\n",
       " 'Hari-Nagarajan',\n",
       " '3b1b',\n",
       " 'lukemelas',\n",
       " 'PostHog',\n",
       " 'huggingface',\n",
       " 'open-mmlab',\n",
       " 'pytorch',\n",
       " 'TheAlgorithms',\n",
       " 'JunMa11',\n",
       " 'ManimCommunity']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_repo = repo_names[0].find_all(\"article\")\n",
    "articles_repo[0].h1.a.span.string\n",
    "\n",
    "[str(art.h1.a.span.string).replace(' ','')\n",
    " .replace('\\n','').replace('/','')\n",
    " for art in articles_repo]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display all the image links from Walt Disney wikipedia page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url3 = 'https://en.wikipedia.org/wiki/Walt_Disney'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "html3 = requests.get(url3).content\n",
    "code_source_image = BeautifulSoup(html3, \"html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = code_source_image.find_all(\"img\")\n",
    "images\n",
    "\n",
    "link_images = [str(images).split(\"src\") for image in images]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = code_source_image.find_all(\"img\")\n",
    "images\n",
    "\n",
    "link_images2 = [link.get(\"src\") for link in images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve an arbitary Wikipedia page of \"Python\" and create a list of links on that page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url4 ='https://en.wikipedia.org/wiki/Python' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "html4 = requests.get(url4).content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " '#mw-head',\n",
       " '#searchInput',\n",
       " 'https://en.wiktionary.org/wiki/Python',\n",
       " 'https://en.wiktionary.org/wiki/python',\n",
       " '/wiki/Pythons',\n",
       " '/wiki/Python_(genus)',\n",
       " '#Computing',\n",
       " '#People',\n",
       " '#Roller_coasters',\n",
       " '#Vehicles',\n",
       " '#Weaponry',\n",
       " '#Other_uses',\n",
       " '#See_also',\n",
       " '/w/index.php?title=Python&action=edit&section=1',\n",
       " '/wiki/Python_(programming_language)',\n",
       " '/wiki/CMU_Common_Lisp',\n",
       " '/wiki/PERQ#PERQ_3',\n",
       " '/w/index.php?title=Python&action=edit&section=2',\n",
       " '/wiki/Python_of_Aenus',\n",
       " '/wiki/Python_(painter)',\n",
       " '/wiki/Python_of_Byzantium',\n",
       " '/wiki/Python_of_Catana',\n",
       " '/wiki/Python_Anghelo',\n",
       " '/w/index.php?title=Python&action=edit&section=3',\n",
       " '/wiki/Python_(Efteling)',\n",
       " '/wiki/Python_(Busch_Gardens_Tampa_Bay)',\n",
       " '/wiki/Python_(Coney_Island,_Cincinnati,_Ohio)',\n",
       " '/w/index.php?title=Python&action=edit&section=4',\n",
       " '/wiki/Python_(automobile_maker)',\n",
       " '/wiki/Python_(Ford_prototype)',\n",
       " '/w/index.php?title=Python&action=edit&section=5',\n",
       " '/wiki/Python_(missile)',\n",
       " '/wiki/Python_(nuclear_primary)',\n",
       " '/wiki/Colt_Python',\n",
       " '/w/index.php?title=Python&action=edit&section=6',\n",
       " '/wiki/PYTHON',\n",
       " '/wiki/Python_(film)',\n",
       " '/wiki/Python_(mythology)',\n",
       " '/wiki/Monty_Python',\n",
       " '/wiki/Python_(Monty)_Pictures',\n",
       " '/w/index.php?title=Python&action=edit&section=7',\n",
       " '/wiki/Cython',\n",
       " '/wiki/Pyton',\n",
       " '/wiki/Pithon',\n",
       " '/wiki/File:Disambig_gray.svg',\n",
       " '/wiki/Help:Disambiguation',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Special:WhatLinksHere/Python&namespace=0',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Python&oldid=997582414',\n",
       " '/wiki/Help:Category',\n",
       " '/wiki/Category:Disambiguation_pages',\n",
       " '/wiki/Category:Human_name_disambiguation_pages',\n",
       " '/wiki/Category:Disambiguation_pages_with_given-name-holder_lists',\n",
       " '/wiki/Category:Disambiguation_pages_with_short_descriptions',\n",
       " '/wiki/Category:Short_description_is_different_from_Wikidata',\n",
       " '/wiki/Category:All_article_disambiguation_pages',\n",
       " '/wiki/Category:All_disambiguation_pages',\n",
       " '/wiki/Category:Animal_common_name_disambiguation_pages',\n",
       " '/wiki/Special:MyTalk',\n",
       " '/wiki/Special:MyContributions',\n",
       " '/w/index.php?title=Special:CreateAccount&returnto=Python',\n",
       " '/w/index.php?title=Special:UserLogin&returnto=Python',\n",
       " '/wiki/Python',\n",
       " '/wiki/Talk:Python',\n",
       " '/wiki/Python',\n",
       " '/w/index.php?title=Python&action=edit',\n",
       " '/w/index.php?title=Python&action=history',\n",
       " '/wiki/Main_Page',\n",
       " '/wiki/Main_Page',\n",
       " '/wiki/Wikipedia:Contents',\n",
       " '/wiki/Portal:Current_events',\n",
       " '/wiki/Special:Random',\n",
       " '/wiki/Wikipedia:About',\n",
       " '//en.wikipedia.org/wiki/Wikipedia:Contact_us',\n",
       " 'https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en',\n",
       " '/wiki/Help:Contents',\n",
       " '/wiki/Help:Introduction',\n",
       " '/wiki/Wikipedia:Community_portal',\n",
       " '/wiki/Special:RecentChanges',\n",
       " '/wiki/Wikipedia:File_Upload_Wizard',\n",
       " '/wiki/Special:WhatLinksHere/Python',\n",
       " '/wiki/Special:RecentChangesLinked/Python',\n",
       " '/wiki/Wikipedia:File_Upload_Wizard',\n",
       " '/wiki/Special:SpecialPages',\n",
       " '/w/index.php?title=Python&oldid=997582414',\n",
       " '/w/index.php?title=Python&action=info',\n",
       " '/w/index.php?title=Special:CiteThisPage&page=Python&id=997582414&wpFormIdentifier=titleform',\n",
       " 'https://www.wikidata.org/wiki/Special:EntityPage/Q747452',\n",
       " '/w/index.php?title=Special:DownloadAsPdf&page=Python&action=show-download-screen',\n",
       " '/w/index.php?title=Python&printable=yes',\n",
       " 'https://commons.wikimedia.org/wiki/Category:Python',\n",
       " 'https://af.wikipedia.org/wiki/Python',\n",
       " 'https://als.wikipedia.org/wiki/Python',\n",
       " 'https://ar.wikipedia.org/wiki/%D8%A8%D8%A7%D9%8A%D8%AB%D9%88%D9%86_(%D8%AA%D9%88%D8%B6%D9%8A%D8%AD)',\n",
       " 'https://az.wikipedia.org/wiki/Python',\n",
       " 'https://bn.wikipedia.org/wiki/%E0%A6%AA%E0%A6%BE%E0%A6%87%E0%A6%A5%E0%A6%A8_(%E0%A6%A6%E0%A7%8D%E0%A6%AC%E0%A7%8D%E0%A6%AF%E0%A6%B0%E0%A7%8D%E0%A6%A5%E0%A6%A4%E0%A6%BE_%E0%A6%A8%E0%A6%BF%E0%A6%B0%E0%A6%B8%E0%A6%A8)',\n",
       " 'https://be.wikipedia.org/wiki/Python',\n",
       " 'https://bg.wikipedia.org/wiki/%D0%9F%D0%B8%D1%82%D0%BE%D0%BD_(%D0%BF%D0%BE%D1%8F%D1%81%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5)',\n",
       " 'https://cs.wikipedia.org/wiki/Python_(rozcestn%C3%ADk)',\n",
       " 'https://da.wikipedia.org/wiki/Python',\n",
       " 'https://de.wikipedia.org/wiki/Python',\n",
       " 'https://eo.wikipedia.org/wiki/Pitono_(apartigilo)',\n",
       " 'https://eu.wikipedia.org/wiki/Python_(argipena)',\n",
       " 'https://fa.wikipedia.org/wiki/%D9%BE%D8%A7%DB%8C%D8%AA%D9%88%D9%86',\n",
       " 'https://fr.wikipedia.org/wiki/Python',\n",
       " 'https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%9D%B4%EC%84%A0',\n",
       " 'https://hr.wikipedia.org/wiki/Python_(razdvojba)',\n",
       " 'https://io.wikipedia.org/wiki/Pitono',\n",
       " 'https://id.wikipedia.org/wiki/Python',\n",
       " 'https://ia.wikipedia.org/wiki/Python_(disambiguation)',\n",
       " 'https://is.wikipedia.org/wiki/Python_(a%C3%B0greining)',\n",
       " 'https://it.wikipedia.org/wiki/Python_(disambigua)',\n",
       " 'https://he.wikipedia.org/wiki/%D7%A4%D7%99%D7%AA%D7%95%D7%9F',\n",
       " 'https://ka.wikipedia.org/wiki/%E1%83%9E%E1%83%98%E1%83%97%E1%83%9D%E1%83%9C%E1%83%98_(%E1%83%9B%E1%83%A0%E1%83%90%E1%83%95%E1%83%90%E1%83%9A%E1%83%9B%E1%83%9C%E1%83%98%E1%83%A8%E1%83%95%E1%83%9C%E1%83%94%E1%83%9A%E1%83%9D%E1%83%95%E1%83%90%E1%83%9C%E1%83%98)',\n",
       " 'https://kg.wikipedia.org/wiki/Mboma_(nyoka)',\n",
       " 'https://la.wikipedia.org/wiki/Python_(discretiva)',\n",
       " 'https://lb.wikipedia.org/wiki/Python',\n",
       " 'https://hu.wikipedia.org/wiki/Python_(egy%C3%A9rtelm%C5%B1s%C3%ADt%C5%91_lap)',\n",
       " 'https://mr.wikipedia.org/wiki/%E0%A4%AA%E0%A4%BE%E0%A4%AF%E0%A4%A5%E0%A5%89%E0%A4%A8_(%E0%A4%86%E0%A4%9C%E0%A5%8D%E0%A4%9E%E0%A4%BE%E0%A4%B5%E0%A4%B2%E0%A5%80_%E0%A4%AD%E0%A4%BE%E0%A4%B7%E0%A4%BE)',\n",
       " 'https://nl.wikipedia.org/wiki/Python',\n",
       " 'https://ja.wikipedia.org/wiki/%E3%83%91%E3%82%A4%E3%82%BD%E3%83%B3',\n",
       " 'https://no.wikipedia.org/wiki/Pyton',\n",
       " 'https://pl.wikipedia.org/wiki/Pyton',\n",
       " 'https://pt.wikipedia.org/wiki/Python_(desambigua%C3%A7%C3%A3o)',\n",
       " 'https://ru.wikipedia.org/wiki/Python_(%D0%B7%D0%BD%D0%B0%D1%87%D0%B5%D0%BD%D0%B8%D1%8F)',\n",
       " 'https://sk.wikipedia.org/wiki/Python',\n",
       " 'https://sr.wikipedia.org/wiki/%D0%9F%D0%B8%D1%82%D0%BE%D0%BD_(%D0%B2%D0%B8%D1%88%D0%B5%D0%B7%D0%BD%D0%B0%D1%87%D0%BD%D0%B0_%D0%BE%D0%B4%D1%80%D0%B5%D0%B4%D0%BD%D0%B8%D1%86%D0%B0)',\n",
       " 'https://sh.wikipedia.org/wiki/Python',\n",
       " 'https://fi.wikipedia.org/wiki/Python',\n",
       " 'https://sv.wikipedia.org/wiki/Pyton',\n",
       " 'https://th.wikipedia.org/wiki/%E0%B9%84%E0%B8%9E%E0%B8%97%E0%B8%AD%E0%B8%99',\n",
       " 'https://tr.wikipedia.org/wiki/Python',\n",
       " 'https://uk.wikipedia.org/wiki/%D0%9F%D1%96%D1%84%D0%BE%D0%BD',\n",
       " 'https://ur.wikipedia.org/wiki/%D9%BE%D8%A7%D8%A6%DB%8C%D8%AA%DA%BE%D9%88%D9%86',\n",
       " 'https://vi.wikipedia.org/wiki/Python',\n",
       " 'https://zh.wikipedia.org/wiki/Python_(%E6%B6%88%E6%AD%A7%E4%B9%89)',\n",
       " 'https://www.wikidata.org/wiki/Special:EntityPage/Q747452#sitelinks-wikipedia',\n",
       " '//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License',\n",
       " '//creativecommons.org/licenses/by-sa/3.0/',\n",
       " '//foundation.wikimedia.org/wiki/Terms_of_Use',\n",
       " '//foundation.wikimedia.org/wiki/Privacy_policy',\n",
       " '//www.wikimediafoundation.org/',\n",
       " 'https://foundation.wikimedia.org/wiki/Privacy_policy',\n",
       " '/wiki/Wikipedia:About',\n",
       " '/wiki/Wikipedia:General_disclaimer',\n",
       " '//en.wikipedia.org/wiki/Wikipedia:Contact_us',\n",
       " '//en.m.wikipedia.org/w/index.php?title=Python&mobileaction=toggle_view_mobile',\n",
       " 'https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute',\n",
       " 'https://stats.wikimedia.org/#/en.wikipedia.org',\n",
       " 'https://foundation.wikimedia.org/wiki/Cookie_statement',\n",
       " 'https://wikimediafoundation.org/',\n",
       " 'https://www.mediawiki.org/']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup4 = BeautifulSoup(html4, \"html.parser\")\n",
    "soup4_find = soup4.find_all(\"a\")\n",
    "\n",
    "link_list = [link.get(\"href\") for link in soup4_find]\n",
    "link_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the number of titles that have changed in the United States Code since its last release point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url5 = 'http://uscode.house.gov/download/download.shtml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "html5 = requests.get(url5).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup5 = BeautifulSoup(html5, \"html.parser\")\n",
    "soup5_find = soup5.find_all(\"div\",{\"class\":\"usctitlechanged\"})\n",
    "\n",
    "link_titles = [str(soup5_find) for title in soup5_find]\n",
    "len(link_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find a Python list with the top ten FBI's Most Wanted names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url6 = 'https://www.fbi.gov/wanted/topten'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "html6 = requests.get(url6).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "soup6 = BeautifulSoup(html6, \"html.parser\")\n",
    "soup6_find = soup6.find_all(\"div\",{\"class\":\"movable removable mosaic-tile mosaic-castle.cms.querylisting-tile\"})[0]\n",
    "\n",
    "names_fugitives = [str(soup6_find.text).strip().split(\"\\n\") for name in soup6_find]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Display the 20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url7 = 'https://www.emsc-csem.org/Earthquake/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>date&amp;time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>km</th>\n",
       "      <th>mag</th>\n",
       "      <th>region name</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>12:07:53.023min</td>\n",
       "      <td>ago25.78</td>\n",
       "      <td>S</td>\n",
       "      <td>70.44</td>\n",
       "      <td>W</td>\n",
       "      <td>50ML3.0</td>\n",
       "      <td>ANTOFAGASTA,</td>\n",
       "      <td>CHILE2021-04-03</td>\n",
       "      <td>12:25</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>11:56:50.034min</td>\n",
       "      <td>ago8.94</td>\n",
       "      <td>S</td>\n",
       "      <td>122.43</td>\n",
       "      <td>E</td>\n",
       "      <td>103</td>\n",
       "      <td>M4.1</td>\n",
       "      <td>FLORES</td>\n",
       "      <td>REGION,</td>\n",
       "      <td>INDONESIA2021-04-03</td>\n",
       "      <td>12:05</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>11:48:29.042min</td>\n",
       "      <td>ago9.78</td>\n",
       "      <td>S</td>\n",
       "      <td>120.66</td>\n",
       "      <td>E</td>\n",
       "      <td>14</td>\n",
       "      <td>M3.3</td>\n",
       "      <td>SUMBA</td>\n",
       "      <td>REGION,</td>\n",
       "      <td>INDONESIA2021-04-03</td>\n",
       "      <td>11:55</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>11:45:27.745min</td>\n",
       "      <td>ago43.05</td>\n",
       "      <td>N</td>\n",
       "      <td>2.01</td>\n",
       "      <td>W</td>\n",
       "      <td>10ML1.6</td>\n",
       "      <td>SPAIN2021-04-03</td>\n",
       "      <td>11:51</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>11:41:39.049min</td>\n",
       "      <td>ago38.48</td>\n",
       "      <td>N</td>\n",
       "      <td>15.32</td>\n",
       "      <td>E</td>\n",
       "      <td>158ML2.2</td>\n",
       "      <td>SICILY,</td>\n",
       "      <td>ITALY2021-04-03</td>\n",
       "      <td>11:59</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>11:31:30.059min</td>\n",
       "      <td>ago39.59</td>\n",
       "      <td>N</td>\n",
       "      <td>38.17</td>\n",
       "      <td>E</td>\n",
       "      <td>13ML2.0</td>\n",
       "      <td>EASTERN</td>\n",
       "      <td>TURKEY2021-04-03</td>\n",
       "      <td>12:09</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>11:30:28.01hr</td>\n",
       "      <td>00min</td>\n",
       "      <td>ago32.47</td>\n",
       "      <td>S</td>\n",
       "      <td>71.67</td>\n",
       "      <td>W</td>\n",
       "      <td>61ML3.5</td>\n",
       "      <td>OFFSHORE</td>\n",
       "      <td>VALPARAISO,</td>\n",
       "      <td>CHILE2021-04-03</td>\n",
       "      <td>11:52</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>11:27:01.01hr</td>\n",
       "      <td>03min</td>\n",
       "      <td>ago0.07</td>\n",
       "      <td>N</td>\n",
       "      <td>121.93</td>\n",
       "      <td>E</td>\n",
       "      <td>10</td>\n",
       "      <td>M2.6</td>\n",
       "      <td>MINAHASA,</td>\n",
       "      <td>SULAWESI,</td>\n",
       "      <td>INDONESIA2021-04-03</td>\n",
       "      <td>11:55</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>11:23:38.91hr</td>\n",
       "      <td>07min</td>\n",
       "      <td>ago27.89</td>\n",
       "      <td>N</td>\n",
       "      <td>16.32</td>\n",
       "      <td>W</td>\n",
       "      <td>1ML1.6</td>\n",
       "      <td>CANARY</td>\n",
       "      <td>ISLANDS,</td>\n",
       "      <td>SPAIN</td>\n",
       "      <td>REGION2021-04-03</td>\n",
       "      <td>11:40</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>11:11:29.71hr</td>\n",
       "      <td>19min</td>\n",
       "      <td>ago57.85</td>\n",
       "      <td>S</td>\n",
       "      <td>7.62</td>\n",
       "      <td>W</td>\n",
       "      <td>10mb5.0</td>\n",
       "      <td>EAST</td>\n",
       "      <td>OF</td>\n",
       "      <td>SOUTH</td>\n",
       "      <td>SANDWICH</td>\n",
       "      <td>ISLANDS2021-04-03</td>\n",
       "      <td>11:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>11:01:03.81hr</td>\n",
       "      <td>29min</td>\n",
       "      <td>ago42.31</td>\n",
       "      <td>N</td>\n",
       "      <td>1.61</td>\n",
       "      <td>E</td>\n",
       "      <td>10ML2.0</td>\n",
       "      <td>PYRENEES2021-04-03</td>\n",
       "      <td>11:10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>10:58:36.61hr</td>\n",
       "      <td>32min</td>\n",
       "      <td>ago19.34</td>\n",
       "      <td>N</td>\n",
       "      <td>155.13</td>\n",
       "      <td>W</td>\n",
       "      <td>4Md2.2</td>\n",
       "      <td>ISLAND</td>\n",
       "      <td>OF</td>\n",
       "      <td>HAWAII,</td>\n",
       "      <td>HAWAII2021-04-03</td>\n",
       "      <td>11:01</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>10:57:33.61hr</td>\n",
       "      <td>33min</td>\n",
       "      <td>ago42.29</td>\n",
       "      <td>N</td>\n",
       "      <td>1.63</td>\n",
       "      <td>E</td>\n",
       "      <td>2ML2.3</td>\n",
       "      <td>PYRENEES2021-04-03</td>\n",
       "      <td>11:08</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>10:54:30.41hr</td>\n",
       "      <td>36min</td>\n",
       "      <td>ago19.23</td>\n",
       "      <td>N</td>\n",
       "      <td>155.47</td>\n",
       "      <td>W</td>\n",
       "      <td>44ML3.0</td>\n",
       "      <td>ISLAND</td>\n",
       "      <td>OF</td>\n",
       "      <td>HAWAII,</td>\n",
       "      <td>HAWAII2021-04-03</td>\n",
       "      <td>11:04</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>10:30:15.32hr</td>\n",
       "      <td>00min</td>\n",
       "      <td>ago40.91</td>\n",
       "      <td>N</td>\n",
       "      <td>31.62</td>\n",
       "      <td>E</td>\n",
       "      <td>14ML2.2</td>\n",
       "      <td>WESTERN</td>\n",
       "      <td>TURKEY2021-04-03</td>\n",
       "      <td>11:37</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>10:21:49.42hr</td>\n",
       "      <td>09min</td>\n",
       "      <td>ago19.40</td>\n",
       "      <td>N</td>\n",
       "      <td>155.26</td>\n",
       "      <td>W</td>\n",
       "      <td>34ML2.7</td>\n",
       "      <td>ISLAND</td>\n",
       "      <td>OF</td>\n",
       "      <td>HAWAII,</td>\n",
       "      <td>HAWAII2021-04-03</td>\n",
       "      <td>10:36</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>10:21:32.42hr</td>\n",
       "      <td>09min</td>\n",
       "      <td>ago42.31</td>\n",
       "      <td>N</td>\n",
       "      <td>1.59</td>\n",
       "      <td>E</td>\n",
       "      <td>10ML1.6</td>\n",
       "      <td>PYRENEES2021-04-03</td>\n",
       "      <td>10:35</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>10:17:32.52hr</td>\n",
       "      <td>13min</td>\n",
       "      <td>ago42.33</td>\n",
       "      <td>N</td>\n",
       "      <td>1.61</td>\n",
       "      <td>E</td>\n",
       "      <td>5ML3.6</td>\n",
       "      <td>PYRENEES2021-04-03</td>\n",
       "      <td>10:47</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>10:12:17.32hr</td>\n",
       "      <td>18min</td>\n",
       "      <td>ago35.12</td>\n",
       "      <td>N</td>\n",
       "      <td>95.32</td>\n",
       "      <td>W</td>\n",
       "      <td>0ML2.2</td>\n",
       "      <td>OKLAHOMA2021-04-03</td>\n",
       "      <td>10:17</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>09:52:07.02hr</td>\n",
       "      <td>38min</td>\n",
       "      <td>ago15.94</td>\n",
       "      <td>N</td>\n",
       "      <td>98.84</td>\n",
       "      <td>W</td>\n",
       "      <td>12</td>\n",
       "      <td>M4.1</td>\n",
       "      <td>OFFSHORE</td>\n",
       "      <td>GUERRERO,</td>\n",
       "      <td>MEXICO2021-04-03</td>\n",
       "      <td>10:15</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>09:45:05.32hr</td>\n",
       "      <td>45min</td>\n",
       "      <td>ago42.31</td>\n",
       "      <td>N</td>\n",
       "      <td>1.60</td>\n",
       "      <td>E</td>\n",
       "      <td>1ML1.7</td>\n",
       "      <td>PYRENEES2021-04-03</td>\n",
       "      <td>10:10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>09:40:23.02hr</td>\n",
       "      <td>50min</td>\n",
       "      <td>ago43.62</td>\n",
       "      <td>N</td>\n",
       "      <td>8.76</td>\n",
       "      <td>W</td>\n",
       "      <td>10ML2.3</td>\n",
       "      <td>SPAIN2021-04-03</td>\n",
       "      <td>10:26</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Fearthquake2021-04-03</td>\n",
       "      <td>09:32:21.22hr</td>\n",
       "      <td>58min</td>\n",
       "      <td>ago42.31</td>\n",
       "      <td>N</td>\n",
       "      <td>1.61</td>\n",
       "      <td>E</td>\n",
       "      <td>8ML3.8</td>\n",
       "      <td>PYRENEES2021-04-03</td>\n",
       "      <td>10:05</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>09:31:30.02hr</td>\n",
       "      <td>59min</td>\n",
       "      <td>ago12.34</td>\n",
       "      <td>N</td>\n",
       "      <td>87.48</td>\n",
       "      <td>W</td>\n",
       "      <td>30</td>\n",
       "      <td>M3.0</td>\n",
       "      <td>NEAR</td>\n",
       "      <td>COAST</td>\n",
       "      <td>OF</td>\n",
       "      <td>NICARAGUA2021-04-03</td>\n",
       "      <td>09:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>09:27:02.03hr</td>\n",
       "      <td>03min</td>\n",
       "      <td>ago63.61</td>\n",
       "      <td>N</td>\n",
       "      <td>150.78</td>\n",
       "      <td>W</td>\n",
       "      <td>7ML3.0</td>\n",
       "      <td>CENTRAL</td>\n",
       "      <td>ALASKA2021-04-03</td>\n",
       "      <td>09:42</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>09:17:07.03hr</td>\n",
       "      <td>13min</td>\n",
       "      <td>ago41.11</td>\n",
       "      <td>S</td>\n",
       "      <td>73.49</td>\n",
       "      <td>W</td>\n",
       "      <td>39ML3.9</td>\n",
       "      <td>LOS</td>\n",
       "      <td>LAGOS,</td>\n",
       "      <td>CHILE2021-04-03</td>\n",
       "      <td>09:37</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>09:15:45.23hr</td>\n",
       "      <td>15min</td>\n",
       "      <td>ago28.07</td>\n",
       "      <td>N</td>\n",
       "      <td>16.28</td>\n",
       "      <td>W</td>\n",
       "      <td>34ML1.9</td>\n",
       "      <td>CANARY</td>\n",
       "      <td>ISLANDS,</td>\n",
       "      <td>SPAIN</td>\n",
       "      <td>REGION2021-04-03</td>\n",
       "      <td>09:23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>08:56:39.13hr</td>\n",
       "      <td>34min</td>\n",
       "      <td>ago19.19</td>\n",
       "      <td>N</td>\n",
       "      <td>155.49</td>\n",
       "      <td>W</td>\n",
       "      <td>33Md2.0</td>\n",
       "      <td>ISLAND</td>\n",
       "      <td>OF</td>\n",
       "      <td>HAWAII,</td>\n",
       "      <td>HAWAII2021-04-03</td>\n",
       "      <td>08:59</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>08:48:42.83hr</td>\n",
       "      <td>42min</td>\n",
       "      <td>ago42.89</td>\n",
       "      <td>N</td>\n",
       "      <td>46.43</td>\n",
       "      <td>E</td>\n",
       "      <td>10mb3.9</td>\n",
       "      <td>CAUCASUS</td>\n",
       "      <td>REGION,</td>\n",
       "      <td>RUSSIA2021-04-03</td>\n",
       "      <td>10:04</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>08:15:19.04hr</td>\n",
       "      <td>15min</td>\n",
       "      <td>ago18.64</td>\n",
       "      <td>N</td>\n",
       "      <td>68.77</td>\n",
       "      <td>W</td>\n",
       "      <td>117</td>\n",
       "      <td>M3.0</td>\n",
       "      <td>DOMINICAN</td>\n",
       "      <td>REPUBLIC2021-04-03</td>\n",
       "      <td>11:26</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>08:15:14.34hr</td>\n",
       "      <td>15min</td>\n",
       "      <td>ago39.32</td>\n",
       "      <td>N</td>\n",
       "      <td>46.00</td>\n",
       "      <td>E</td>\n",
       "      <td>1M</td>\n",
       "      <td>2.2</td>\n",
       "      <td>ARMENIA2021-04-03</td>\n",
       "      <td>10:03</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>08:06:00.04hr</td>\n",
       "      <td>25min</td>\n",
       "      <td>ago20.88</td>\n",
       "      <td>S</td>\n",
       "      <td>68.59</td>\n",
       "      <td>W</td>\n",
       "      <td>12ML3.1</td>\n",
       "      <td>TARAPACA,</td>\n",
       "      <td>CHILE2021-04-03</td>\n",
       "      <td>08:22</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>07:44:39.54hr</td>\n",
       "      <td>46min</td>\n",
       "      <td>ago19.06</td>\n",
       "      <td>N</td>\n",
       "      <td>67.24</td>\n",
       "      <td>W</td>\n",
       "      <td>10Md3.2</td>\n",
       "      <td>PUERTO</td>\n",
       "      <td>RICO</td>\n",
       "      <td>REGION2021-04-03</td>\n",
       "      <td>09:18</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>8IVearthquake2021-04-03</td>\n",
       "      <td>07:39:56.14hr</td>\n",
       "      <td>51min</td>\n",
       "      <td>ago37.90</td>\n",
       "      <td>N</td>\n",
       "      <td>27.15</td>\n",
       "      <td>E</td>\n",
       "      <td>5ML3.1</td>\n",
       "      <td>WESTERN</td>\n",
       "      <td>TURKEY2021-04-03</td>\n",
       "      <td>10:23</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Fearthquake2021-04-03</td>\n",
       "      <td>07:36:46.14hr</td>\n",
       "      <td>54min</td>\n",
       "      <td>ago37.89</td>\n",
       "      <td>N</td>\n",
       "      <td>27.15</td>\n",
       "      <td>E</td>\n",
       "      <td>7ML2.2</td>\n",
       "      <td>WESTERN</td>\n",
       "      <td>TURKEY2021-04-03</td>\n",
       "      <td>08:18</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>07:17:26.05hr</td>\n",
       "      <td>13min</td>\n",
       "      <td>ago36.80</td>\n",
       "      <td>N</td>\n",
       "      <td>121.53</td>\n",
       "      <td>W</td>\n",
       "      <td>7Md2.7</td>\n",
       "      <td>CENTRAL</td>\n",
       "      <td>CALIFORNIA2021-04-03</td>\n",
       "      <td>07:19</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>07:13:46.05hr</td>\n",
       "      <td>17min</td>\n",
       "      <td>ago8.71</td>\n",
       "      <td>S</td>\n",
       "      <td>117.41</td>\n",
       "      <td>E</td>\n",
       "      <td>134</td>\n",
       "      <td>M2.8</td>\n",
       "      <td>SUMBAWA</td>\n",
       "      <td>REGION,</td>\n",
       "      <td>INDONESIA2021-04-03</td>\n",
       "      <td>07:25</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>07:05:09.65hr</td>\n",
       "      <td>25min</td>\n",
       "      <td>ago18.01</td>\n",
       "      <td>N</td>\n",
       "      <td>66.75</td>\n",
       "      <td>W</td>\n",
       "      <td>13Md2.1</td>\n",
       "      <td>PUERTO</td>\n",
       "      <td>RICO2021-04-03</td>\n",
       "      <td>08:02</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>07:00:01.65hr</td>\n",
       "      <td>30min</td>\n",
       "      <td>ago36.52</td>\n",
       "      <td>N</td>\n",
       "      <td>27.22</td>\n",
       "      <td>E</td>\n",
       "      <td>5ML2.1</td>\n",
       "      <td>DODECANESE</td>\n",
       "      <td>IS.-TURKEY</td>\n",
       "      <td>BORDER</td>\n",
       "      <td>REG2021-04-03</td>\n",
       "      <td>08:20</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>06:51:29.35hr</td>\n",
       "      <td>39min</td>\n",
       "      <td>ago36.53</td>\n",
       "      <td>N</td>\n",
       "      <td>27.28</td>\n",
       "      <td>E</td>\n",
       "      <td>22ML2.4</td>\n",
       "      <td>DODECANESE</td>\n",
       "      <td>IS.-TURKEY</td>\n",
       "      <td>BORDER</td>\n",
       "      <td>REG2021-04-03</td>\n",
       "      <td>07:36</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>06:48:49.85hr</td>\n",
       "      <td>42min</td>\n",
       "      <td>ago36.51</td>\n",
       "      <td>N</td>\n",
       "      <td>27.14</td>\n",
       "      <td>E</td>\n",
       "      <td>17ML2.1</td>\n",
       "      <td>DODECANESE</td>\n",
       "      <td>IS.-TURKEY</td>\n",
       "      <td>BORDER</td>\n",
       "      <td>REG2021-04-03</td>\n",
       "      <td>07:30</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>06:13:44.56hr</td>\n",
       "      <td>17min</td>\n",
       "      <td>ago17.90</td>\n",
       "      <td>N</td>\n",
       "      <td>66.86</td>\n",
       "      <td>W</td>\n",
       "      <td>14Md2.5</td>\n",
       "      <td>PUERTO</td>\n",
       "      <td>RICO</td>\n",
       "      <td>REGION2021-04-03</td>\n",
       "      <td>07:01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>06:11:54.86hr</td>\n",
       "      <td>19min</td>\n",
       "      <td>ago38.55</td>\n",
       "      <td>N</td>\n",
       "      <td>28.07</td>\n",
       "      <td>E</td>\n",
       "      <td>7ML2.2</td>\n",
       "      <td>WESTERN</td>\n",
       "      <td>TURKEY2021-04-03</td>\n",
       "      <td>06:31</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>06:10:37.46hr</td>\n",
       "      <td>20min</td>\n",
       "      <td>ago38.54</td>\n",
       "      <td>N</td>\n",
       "      <td>28.02</td>\n",
       "      <td>E</td>\n",
       "      <td>7ML2.5</td>\n",
       "      <td>WESTERN</td>\n",
       "      <td>TURKEY2021-04-03</td>\n",
       "      <td>06:29</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Fearthquake2021-04-03</td>\n",
       "      <td>06:10:10.86hr</td>\n",
       "      <td>20min</td>\n",
       "      <td>ago35.05</td>\n",
       "      <td>N</td>\n",
       "      <td>22.65</td>\n",
       "      <td>E</td>\n",
       "      <td>10mb4.6</td>\n",
       "      <td>CENTRAL</td>\n",
       "      <td>MEDITERRANEAN</td>\n",
       "      <td>SEA2021-04-03</td>\n",
       "      <td>06:25</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>05:55:42.06hr</td>\n",
       "      <td>35min</td>\n",
       "      <td>ago20.16</td>\n",
       "      <td>N</td>\n",
       "      <td>72.35</td>\n",
       "      <td>W</td>\n",
       "      <td>10</td>\n",
       "      <td>M3.3</td>\n",
       "      <td>HAITI</td>\n",
       "      <td>REGION2021-04-03</td>\n",
       "      <td>11:05</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>05:36:56.06hr</td>\n",
       "      <td>54min</td>\n",
       "      <td>ago22.74</td>\n",
       "      <td>S</td>\n",
       "      <td>66.25</td>\n",
       "      <td>W</td>\n",
       "      <td>267</td>\n",
       "      <td>M3.4</td>\n",
       "      <td>JUJUY,</td>\n",
       "      <td>ARGENTINA2021-04-03</td>\n",
       "      <td>05:45</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>05:36:26.06hr</td>\n",
       "      <td>54min</td>\n",
       "      <td>ago1.20</td>\n",
       "      <td>N</td>\n",
       "      <td>98.66</td>\n",
       "      <td>E</td>\n",
       "      <td>45</td>\n",
       "      <td>M4.2</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>SUMATRA,</td>\n",
       "      <td>INDONESIA2021-04-03</td>\n",
       "      <td>05:40</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>05:31:19.06hr</td>\n",
       "      <td>59min</td>\n",
       "      <td>ago18.80</td>\n",
       "      <td>N</td>\n",
       "      <td>69.23</td>\n",
       "      <td>W</td>\n",
       "      <td>83</td>\n",
       "      <td>M2.8</td>\n",
       "      <td>DOMINICAN</td>\n",
       "      <td>REPUBLIC2021-04-03</td>\n",
       "      <td>10:50</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>earthquake2021-04-03</td>\n",
       "      <td>05:13:48.07hr</td>\n",
       "      <td>17min</td>\n",
       "      <td>ago28.87</td>\n",
       "      <td>S</td>\n",
       "      <td>71.49</td>\n",
       "      <td>W</td>\n",
       "      <td>29ML2.6</td>\n",
       "      <td>ATACAMA,</td>\n",
       "      <td>CHILE2021-04-03</td>\n",
       "      <td>08:32</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>12345678910›»</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   response        date&time  latitude longitude      km  \\\n",
       "0      earthquake2021-04-03  12:07:53.023min  ago25.78         S   70.44   \n",
       "1      earthquake2021-04-03  11:56:50.034min   ago8.94         S  122.43   \n",
       "2      earthquake2021-04-03  11:48:29.042min   ago9.78         S  120.66   \n",
       "3      earthquake2021-04-03  11:45:27.745min  ago43.05         N    2.01   \n",
       "4      earthquake2021-04-03  11:41:39.049min  ago38.48         N   15.32   \n",
       "5      earthquake2021-04-03  11:31:30.059min  ago39.59         N   38.17   \n",
       "6      earthquake2021-04-03    11:30:28.01hr     00min  ago32.47       S   \n",
       "7      earthquake2021-04-03    11:27:01.01hr     03min   ago0.07       N   \n",
       "8      earthquake2021-04-03    11:23:38.91hr     07min  ago27.89       N   \n",
       "9      earthquake2021-04-03    11:11:29.71hr     19min  ago57.85       S   \n",
       "10     earthquake2021-04-03    11:01:03.81hr     29min  ago42.31       N   \n",
       "11     earthquake2021-04-03    10:58:36.61hr     32min  ago19.34       N   \n",
       "12     earthquake2021-04-03    10:57:33.61hr     33min  ago42.29       N   \n",
       "13     earthquake2021-04-03    10:54:30.41hr     36min  ago19.23       N   \n",
       "14     earthquake2021-04-03    10:30:15.32hr     00min  ago40.91       N   \n",
       "15     earthquake2021-04-03    10:21:49.42hr     09min  ago19.40       N   \n",
       "16     earthquake2021-04-03    10:21:32.42hr     09min  ago42.31       N   \n",
       "17     earthquake2021-04-03    10:17:32.52hr     13min  ago42.33       N   \n",
       "18     earthquake2021-04-03    10:12:17.32hr     18min  ago35.12       N   \n",
       "19     earthquake2021-04-03    09:52:07.02hr     38min  ago15.94       N   \n",
       "20     earthquake2021-04-03    09:45:05.32hr     45min  ago42.31       N   \n",
       "21     earthquake2021-04-03    09:40:23.02hr     50min  ago43.62       N   \n",
       "22    Fearthquake2021-04-03    09:32:21.22hr     58min  ago42.31       N   \n",
       "23     earthquake2021-04-03    09:31:30.02hr     59min  ago12.34       N   \n",
       "24     earthquake2021-04-03    09:27:02.03hr     03min  ago63.61       N   \n",
       "25     earthquake2021-04-03    09:17:07.03hr     13min  ago41.11       S   \n",
       "26     earthquake2021-04-03    09:15:45.23hr     15min  ago28.07       N   \n",
       "27     earthquake2021-04-03    08:56:39.13hr     34min  ago19.19       N   \n",
       "28     earthquake2021-04-03    08:48:42.83hr     42min  ago42.89       N   \n",
       "29     earthquake2021-04-03    08:15:19.04hr     15min  ago18.64       N   \n",
       "30     earthquake2021-04-03    08:15:14.34hr     15min  ago39.32       N   \n",
       "31     earthquake2021-04-03    08:06:00.04hr     25min  ago20.88       S   \n",
       "32     earthquake2021-04-03    07:44:39.54hr     46min  ago19.06       N   \n",
       "33  8IVearthquake2021-04-03    07:39:56.14hr     51min  ago37.90       N   \n",
       "34    Fearthquake2021-04-03    07:36:46.14hr     54min  ago37.89       N   \n",
       "35     earthquake2021-04-03    07:17:26.05hr     13min  ago36.80       N   \n",
       "36     earthquake2021-04-03    07:13:46.05hr     17min   ago8.71       S   \n",
       "37     earthquake2021-04-03    07:05:09.65hr     25min  ago18.01       N   \n",
       "38     earthquake2021-04-03    07:00:01.65hr     30min  ago36.52       N   \n",
       "39     earthquake2021-04-03    06:51:29.35hr     39min  ago36.53       N   \n",
       "40     earthquake2021-04-03    06:48:49.85hr     42min  ago36.51       N   \n",
       "41     earthquake2021-04-03    06:13:44.56hr     17min  ago17.90       N   \n",
       "42     earthquake2021-04-03    06:11:54.86hr     19min  ago38.55       N   \n",
       "43     earthquake2021-04-03    06:10:37.46hr     20min  ago38.54       N   \n",
       "44    Fearthquake2021-04-03    06:10:10.86hr     20min  ago35.05       N   \n",
       "45     earthquake2021-04-03    05:55:42.06hr     35min  ago20.16       N   \n",
       "46     earthquake2021-04-03    05:36:56.06hr     54min  ago22.74       S   \n",
       "47     earthquake2021-04-03    05:36:26.06hr     54min   ago1.20       N   \n",
       "48     earthquake2021-04-03    05:31:19.06hr     59min  ago18.80       N   \n",
       "49     earthquake2021-04-03    05:13:48.07hr     17min  ago28.87       S   \n",
       "50                     None             None      None      None    None   \n",
       "51            12345678910›»             None      None      None    None   \n",
       "52                     None             None      None      None    None   \n",
       "\n",
       "       mag region name                0                   0  \\\n",
       "0        W     50ML3.0     ANTOFAGASTA,     CHILE2021-04-03   \n",
       "1        E         103             M4.1              FLORES   \n",
       "2        E          14             M3.3               SUMBA   \n",
       "3        W     10ML1.6  SPAIN2021-04-03               11:51   \n",
       "4        E    158ML2.2          SICILY,     ITALY2021-04-03   \n",
       "5        E     13ML2.0          EASTERN    TURKEY2021-04-03   \n",
       "6    71.67           W          61ML3.5            OFFSHORE   \n",
       "7   121.93           E               10                M2.6   \n",
       "8    16.32           W           1ML1.6              CANARY   \n",
       "9     7.62           W          10mb5.0                EAST   \n",
       "10    1.61           E          10ML2.0  PYRENEES2021-04-03   \n",
       "11  155.13           W           4Md2.2              ISLAND   \n",
       "12    1.63           E           2ML2.3  PYRENEES2021-04-03   \n",
       "13  155.47           W          44ML3.0              ISLAND   \n",
       "14   31.62           E          14ML2.2             WESTERN   \n",
       "15  155.26           W          34ML2.7              ISLAND   \n",
       "16    1.59           E          10ML1.6  PYRENEES2021-04-03   \n",
       "17    1.61           E           5ML3.6  PYRENEES2021-04-03   \n",
       "18   95.32           W           0ML2.2  OKLAHOMA2021-04-03   \n",
       "19   98.84           W               12                M4.1   \n",
       "20    1.60           E           1ML1.7  PYRENEES2021-04-03   \n",
       "21    8.76           W          10ML2.3     SPAIN2021-04-03   \n",
       "22    1.61           E           8ML3.8  PYRENEES2021-04-03   \n",
       "23   87.48           W               30                M3.0   \n",
       "24  150.78           W           7ML3.0             CENTRAL   \n",
       "25   73.49           W          39ML3.9                 LOS   \n",
       "26   16.28           W          34ML1.9              CANARY   \n",
       "27  155.49           W          33Md2.0              ISLAND   \n",
       "28   46.43           E          10mb3.9            CAUCASUS   \n",
       "29   68.77           W              117                M3.0   \n",
       "30   46.00           E               1M                 2.2   \n",
       "31   68.59           W          12ML3.1           TARAPACA,   \n",
       "32   67.24           W          10Md3.2              PUERTO   \n",
       "33   27.15           E           5ML3.1             WESTERN   \n",
       "34   27.15           E           7ML2.2             WESTERN   \n",
       "35  121.53           W           7Md2.7             CENTRAL   \n",
       "36  117.41           E              134                M2.8   \n",
       "37   66.75           W          13Md2.1              PUERTO   \n",
       "38   27.22           E           5ML2.1          DODECANESE   \n",
       "39   27.28           E          22ML2.4          DODECANESE   \n",
       "40   27.14           E          17ML2.1          DODECANESE   \n",
       "41   66.86           W          14Md2.5              PUERTO   \n",
       "42   28.07           E           7ML2.2             WESTERN   \n",
       "43   28.02           E           7ML2.5             WESTERN   \n",
       "44   22.65           E          10mb4.6             CENTRAL   \n",
       "45   72.35           W               10                M3.3   \n",
       "46   66.25           W              267                M3.4   \n",
       "47   98.66           E               45                M4.2   \n",
       "48   69.23           W               83                M2.8   \n",
       "49   71.49           W          29ML2.6            ATACAMA,   \n",
       "50    None        None             None                None   \n",
       "51    None        None             None                None   \n",
       "52    None        None             None                None   \n",
       "\n",
       "                       0                    0                    0  \\\n",
       "0                  12:25                 None                 None   \n",
       "1                REGION,  INDONESIA2021-04-03                12:05   \n",
       "2                REGION,  INDONESIA2021-04-03                11:55   \n",
       "3                   None                 None                 None   \n",
       "4                  11:59                 None                 None   \n",
       "5                  12:09                 None                 None   \n",
       "6            VALPARAISO,      CHILE2021-04-03                11:52   \n",
       "7              MINAHASA,            SULAWESI,  INDONESIA2021-04-03   \n",
       "8               ISLANDS,                SPAIN     REGION2021-04-03   \n",
       "9                     OF                SOUTH             SANDWICH   \n",
       "10                 11:10                 None                 None   \n",
       "11                    OF              HAWAII,     HAWAII2021-04-03   \n",
       "12                 11:08                 None                 None   \n",
       "13                    OF              HAWAII,     HAWAII2021-04-03   \n",
       "14      TURKEY2021-04-03                11:37                 None   \n",
       "15                    OF              HAWAII,     HAWAII2021-04-03   \n",
       "16                 10:35                 None                 None   \n",
       "17                 10:47                 None                 None   \n",
       "18                 10:17                 None                 None   \n",
       "19              OFFSHORE            GUERRERO,     MEXICO2021-04-03   \n",
       "20                 10:10                 None                 None   \n",
       "21                 10:26                 None                 None   \n",
       "22                 10:05                 None                 None   \n",
       "23                  NEAR                COAST                   OF   \n",
       "24      ALASKA2021-04-03                09:42                 None   \n",
       "25                LAGOS,      CHILE2021-04-03                09:37   \n",
       "26              ISLANDS,                SPAIN     REGION2021-04-03   \n",
       "27                    OF              HAWAII,     HAWAII2021-04-03   \n",
       "28               REGION,     RUSSIA2021-04-03                10:04   \n",
       "29             DOMINICAN   REPUBLIC2021-04-03                11:26   \n",
       "30     ARMENIA2021-04-03                10:03                 None   \n",
       "31       CHILE2021-04-03                08:22                 None   \n",
       "32                  RICO     REGION2021-04-03                09:18   \n",
       "33      TURKEY2021-04-03                10:23                 None   \n",
       "34      TURKEY2021-04-03                08:18                 None   \n",
       "35  CALIFORNIA2021-04-03                07:19                 None   \n",
       "36               SUMBAWA              REGION,  INDONESIA2021-04-03   \n",
       "37        RICO2021-04-03                08:02                 None   \n",
       "38            IS.-TURKEY               BORDER        REG2021-04-03   \n",
       "39            IS.-TURKEY               BORDER        REG2021-04-03   \n",
       "40            IS.-TURKEY               BORDER        REG2021-04-03   \n",
       "41                  RICO     REGION2021-04-03                07:01   \n",
       "42      TURKEY2021-04-03                06:31                 None   \n",
       "43      TURKEY2021-04-03                06:29                 None   \n",
       "44         MEDITERRANEAN        SEA2021-04-03                06:25   \n",
       "45                 HAITI     REGION2021-04-03                11:05   \n",
       "46                JUJUY,  ARGENTINA2021-04-03                05:45   \n",
       "47              NORTHERN             SUMATRA,  INDONESIA2021-04-03   \n",
       "48             DOMINICAN   REPUBLIC2021-04-03                10:50   \n",
       "49       CHILE2021-04-03                08:32                 None   \n",
       "50                  None                 None                 None   \n",
       "51                  None                 None                 None   \n",
       "52                  None                 None                 None   \n",
       "\n",
       "                      0      0  \n",
       "0                  None   None  \n",
       "1                  None   None  \n",
       "2                  None   None  \n",
       "3                  None   None  \n",
       "4                  None   None  \n",
       "5                  None   None  \n",
       "6                  None   None  \n",
       "7                 11:55   None  \n",
       "8                 11:40   None  \n",
       "9     ISLANDS2021-04-03  11:35  \n",
       "10                 None   None  \n",
       "11                11:01   None  \n",
       "12                 None   None  \n",
       "13                11:04   None  \n",
       "14                 None   None  \n",
       "15                10:36   None  \n",
       "16                 None   None  \n",
       "17                 None   None  \n",
       "18                 None   None  \n",
       "19                10:15   None  \n",
       "20                 None   None  \n",
       "21                 None   None  \n",
       "22                 None   None  \n",
       "23  NICARAGUA2021-04-03  09:45  \n",
       "24                 None   None  \n",
       "25                 None   None  \n",
       "26                09:23   None  \n",
       "27                08:59   None  \n",
       "28                 None   None  \n",
       "29                 None   None  \n",
       "30                 None   None  \n",
       "31                 None   None  \n",
       "32                 None   None  \n",
       "33                 None   None  \n",
       "34                 None   None  \n",
       "35                 None   None  \n",
       "36                07:25   None  \n",
       "37                 None   None  \n",
       "38                08:20   None  \n",
       "39                07:36   None  \n",
       "40                07:30   None  \n",
       "41                 None   None  \n",
       "42                 None   None  \n",
       "43                 None   None  \n",
       "44                 None   None  \n",
       "45                 None   None  \n",
       "46                 None   None  \n",
       "47                05:40   None  \n",
       "48                 None   None  \n",
       "49                 None   None  \n",
       "50                 None   None  \n",
       "51                 None   None  \n",
       "52                 None   None  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html7 = requests.get(url7).content\n",
    "\n",
    "soup7 = BeautifulSoup(html7, \"html.parser\")\n",
    "soup7_find = soup7.find_all(\"table\")[3]\n",
    "\n",
    "\n",
    "rows = soup7_find(\"tr\")\n",
    "rows = [row.text.split() for row in rows]\n",
    "\n",
    "colnames = ('response', 'date&time', 'latitude', 'longitude', 'km', 'mag', 'region name', '0', '0', '0', '0', '0', '0', '0')\n",
    "data = rows[5:]\n",
    "\n",
    "df_soup7_find = pd.DataFrame(data, columns = colnames)\n",
    "df_soup7_find\n",
    "\n",
    "#for d in soup7_find:\n",
    " #   response = soup7.find_all(\"td\", {\"class\":\"tablev6\"})\n",
    "  #  print(response)\n",
    "    \n",
    "    \n",
    "\"\"\"res = []\n",
    "for book in soup.find_all('li', {'class': 'col-xs-6 col-sm-4 col-md-3 col-lg-3'}):\n",
    "    title = book.h3.a['title']\n",
    "    div_prodprice = book.find('div', {'class': 'product_price'})\n",
    "    price = div_prodprice.find_all('p')[0].text\n",
    "    stock = div_prodprice.find_all('p')[1].text.strip()\n",
    "    res.append([title, price, stock])\n",
    "res_df = pd.DataFrame(res)\"\"\"\n",
    "\n",
    "df_soup7_find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>18:20:03.8</td>\n",
       "      <td>35.09 N</td>\n",
       "      <td>116.97 W</td>\n",
       "      <td>SOUTHERN CALIFORNIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>18:10:30.5</td>\n",
       "      <td>38.14 N</td>\n",
       "      <td>117.85 W</td>\n",
       "      <td>NEVADA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>18:00:44.9</td>\n",
       "      <td>38.80 N</td>\n",
       "      <td>15.71 E</td>\n",
       "      <td>SICILY, ITALY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>17:52:36.7</td>\n",
       "      <td>28.16 N</td>\n",
       "      <td>15.08 W</td>\n",
       "      <td>CANARY ISLANDS, SPAIN REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>17:51:30.0</td>\n",
       "      <td>9.33 N</td>\n",
       "      <td>83.77 W</td>\n",
       "      <td>COSTA RICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>17:42:45.0</td>\n",
       "      <td>4.14 N</td>\n",
       "      <td>96.28 E</td>\n",
       "      <td>NORTHERN SUMATRA, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>17:30:23.0</td>\n",
       "      <td>0.52 N</td>\n",
       "      <td>126.63 E</td>\n",
       "      <td>MOLUCCA SEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>17:29:07.0</td>\n",
       "      <td>19.19 N</td>\n",
       "      <td>155.48 W</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>17:25:17.0</td>\n",
       "      <td>1.33 S</td>\n",
       "      <td>120.55 E</td>\n",
       "      <td>SULAWESI, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>17:14:29.1</td>\n",
       "      <td>34.96 S</td>\n",
       "      <td>179.05 E</td>\n",
       "      <td>SOUTH OF KERMADEC ISLANDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>17:07:32.2</td>\n",
       "      <td>44.39 N</td>\n",
       "      <td>115.17 W</td>\n",
       "      <td>SOUTHERN IDAHO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>17:03:57.0</td>\n",
       "      <td>9.81 N</td>\n",
       "      <td>126.38 E</td>\n",
       "      <td>MINDANAO, PHILIPPINES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>16:51:49.5</td>\n",
       "      <td>35.05 N</td>\n",
       "      <td>96.31 W</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>16:51:32.0</td>\n",
       "      <td>3.86 N</td>\n",
       "      <td>95.92 E</td>\n",
       "      <td>OFF W COAST OF NORTHERN SUMATRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>16:43:03.0</td>\n",
       "      <td>5.58 N</td>\n",
       "      <td>126.04 E</td>\n",
       "      <td>MINDANAO, PHILIPPINES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>16:35:19.3</td>\n",
       "      <td>19.21 N</td>\n",
       "      <td>155.41 W</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>16:22:48.7</td>\n",
       "      <td>44.71 N</td>\n",
       "      <td>11.81 E</td>\n",
       "      <td>NORTHERN ITALY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>16:02:30.0</td>\n",
       "      <td>10.53 N</td>\n",
       "      <td>85.38 W</td>\n",
       "      <td>COSTA RICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>16:02:07.5</td>\n",
       "      <td>38.49 N</td>\n",
       "      <td>37.04 E</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>15:50:17.0</td>\n",
       "      <td>0.64 N</td>\n",
       "      <td>98.43 E</td>\n",
       "      <td>NIAS REGION, INDONESIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date        Time Latitude Longitude                           Region\n",
       "0   2021-04-07  18:20:03.8  35.09 N  116.97 W              SOUTHERN CALIFORNIA\n",
       "1   2021-04-07  18:10:30.5  38.14 N  117.85 W                           NEVADA\n",
       "2   2021-04-07  18:00:44.9  38.80 N   15.71 E                    SICILY, ITALY\n",
       "3   2021-04-07  17:52:36.7  28.16 N   15.08 W     CANARY ISLANDS, SPAIN REGION\n",
       "4   2021-04-07  17:51:30.0   9.33 N   83.77 W                       COSTA RICA\n",
       "5   2021-04-07  17:42:45.0   4.14 N   96.28 E      NORTHERN SUMATRA, INDONESIA\n",
       "6   2021-04-07  17:30:23.0   0.52 N  126.63 E                      MOLUCCA SEA\n",
       "7   2021-04-07  17:29:07.0  19.19 N  155.48 W         ISLAND OF HAWAII, HAWAII\n",
       "8   2021-04-07  17:25:17.0   1.33 S  120.55 E              SULAWESI, INDONESIA\n",
       "9   2021-04-07  17:14:29.1  34.96 S  179.05 E        SOUTH OF KERMADEC ISLANDS\n",
       "10  2021-04-07  17:07:32.2  44.39 N  115.17 W                   SOUTHERN IDAHO\n",
       "11  2021-04-07  17:03:57.0   9.81 N  126.38 E            MINDANAO, PHILIPPINES\n",
       "12  2021-04-07  16:51:49.5  35.05 N   96.31 W                         OKLAHOMA\n",
       "13  2021-04-07  16:51:32.0   3.86 N   95.92 E  OFF W COAST OF NORTHERN SUMATRA\n",
       "14  2021-04-07  16:43:03.0   5.58 N  126.04 E            MINDANAO, PHILIPPINES\n",
       "15  2021-04-07  16:35:19.3  19.21 N  155.41 W         ISLAND OF HAWAII, HAWAII\n",
       "16  2021-04-07  16:22:48.7  44.71 N   11.81 E                   NORTHERN ITALY\n",
       "17  2021-04-07  16:02:30.0  10.53 N   85.38 W                       COSTA RICA\n",
       "18  2021-04-07  16:02:07.5  38.49 N   37.04 E                   CENTRAL TURKEY\n",
       "19  2021-04-07  15:50:17.0   0.64 N   98.43 E           NIAS REGION, INDONESIA"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html7 = requests.get(url7).content;\n",
    "soup = BeautifulSoup(html7, \"lxml\");\n",
    "earthquakes = soup.find('tbody', {'id': 'tbody'}).find_all(\"tr\");\n",
    "\n",
    "nelem = 20;\n",
    "latest_earthquakes = [];\n",
    "    \n",
    "for earthquake in earthquakes[:nelem]:\n",
    "    # Date and time\n",
    "    date, time = earthquake.find('td', {'class': 'tabev6'}).find('a').text.split();\n",
    "    # Latitude and longitude (on peut mettre plusieurs variables avec même find_all)\n",
    "    lat_deg, lon_deg = earthquake.find_all('td', {'class': 'tabev1'});\n",
    "    lat_dir, lon_dir, magnitude = earthquake.find_all('td', {'class': 'tabev2'});\n",
    "    lat_deg = f\"{lat_deg.text.strip()} {lat_dir.text.strip()}\";\n",
    "    lon_deg = f\"{lon_deg.text.strip()} {lon_dir.text.strip()}\";\n",
    "    # Region\n",
    "    region = earthquake.find('td', {'class': 'tb_region'}).text.strip();\n",
    "    # Create list of information and append\n",
    "    earthquake_summary = [date, time, lat_deg , lon_deg, region];\n",
    "    latest_earthquakes.append(earthquake_summary);\n",
    "    \n",
    "df = pd.DataFrame(latest_earthquakes, columns=['Date', 'Time', 'Latitude', 'Longitude', 'Region']);\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count the number of tweets by a given Twitter account.\n",
    "\n",
    "Pour l'exo web scraping Twitter : Twitter a rajouté en 2020 une protection contre le scraping en forçant l'utilisation du JavaScript. Aussi, la technique utilisant un requests.get ne fonctionne plus.\n",
    "\n",
    "Ask the user for the handle (@handle) of a twitter account. You will need to include a ***try/except block*** for account names not found. \n",
    "<br>***Hint:*** the program should count the number of tweets for any provided account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url8 = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please, input your username:  incautiouswifi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Account name not found...\n"
     ]
    }
   ],
   "source": [
    "username = input('Please, input your username: ')\n",
    "html = requests.get(url8 + username).content;\n",
    "soup = BeautifulSoup(html, \"lxml\");\n",
    "\n",
    "try:\n",
    "    tweet_box = soup.find('li', {'class':'ProfileNav-item ProfileNav-item--tweets is-active'});\n",
    "    tweets = tweet_box.find('a').find('span', {'class':'ProfileNav-value'});\n",
    "    print(\"{} has {} number of tweets.\".format(username, tweets.get('data-count')))\n",
    "except:\n",
    "    print('Account name not found...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of followers of a given twitter account\n",
    "Ask the user for the handle (@handle) of a twitter account. You will need to include a ***try/except block*** for account names not found. \n",
    "<br>***Hint:*** the program should count the followers for any provided account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url9 = 'https://twitter.com/EmmanuelMacron'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "html9 = requests.get(url9).content\n",
    "\n",
    "soup9 = BeautifulSoup(html7, \"html.parser\")\n",
    "soup9_find = soup9.find_all(\"body\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all language names and number of related articles in the order they appear in wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url10 = 'https://www.wikipedia.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['English', '6', '274', '000+', 'articles']\",\n",
       " \"['Español', '1', '668', '000+', 'artículos']\",\n",
       " \"['日本語', '1', '259', '000+', '記事']\",\n",
       " \"['Deutsch', '2', '553', '000+', 'Artikel']\",\n",
       " \"['Русский', '1', '708', '000+', 'статей']\",\n",
       " \"['Français', '2', '311', '000+', 'articles']\",\n",
       " \"['Italiano', '1', '681', '000+', 'voci']\",\n",
       " \"['中文', '1', '185', '000+', '條目']\",\n",
       " \"['Português', '1', '061', '000+', 'artigos']\",\n",
       " \"['Polski', '1', '463', '000+', 'haseł']\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html10 = requests.get(url10).content\n",
    "\n",
    "soup10 = BeautifulSoup(html10, \"html.parser\")\n",
    "soup10_find = soup10.find_all('a', {'class': 'link-box'})\n",
    "\n",
    "language_list = [\"\".join(str(language.text.split())) for language in soup10_find]\n",
    "\n",
    "\n",
    "language_list\n",
    "\n",
    "#language_number = {language:v for language,v in soup10_find.items}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list with the different kind of datasets available in data.gov.uk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url11 = 'https://data.gov.uk/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Business and economy',\n",
       " 'Crime and justice',\n",
       " 'Defence',\n",
       " 'Education',\n",
       " 'Environment',\n",
       " 'Government',\n",
       " 'Government spending',\n",
       " 'Health',\n",
       " 'Mapping',\n",
       " 'Society',\n",
       " 'Towns and cities',\n",
       " 'Transport',\n",
       " 'Digital service performance',\n",
       " 'Government reference data']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html11 = requests.get(url11).content\n",
    "\n",
    "soup11 = BeautifulSoup(html11, \"html\")\n",
    "\n",
    "soup11_find = soup11.find_all(\"h3\",{\"class\":\"govuk-heading-s dgu-topics__heading\"})\n",
    "\n",
    "topics_list = [str(topic.text) for topic in soup11_find]\n",
    "topics_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the top 10 languages by number of native speakers stored in a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url12 = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Language</th>\n",
       "      <th>Native speakers</th>\n",
       "      <th>Percentageof worldpopulation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mandarin (entire branch)</td>\n",
       "      <td>935 (955)</td>\n",
       "      <td>14.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>390 (405)</td>\n",
       "      <td>5.85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>English</td>\n",
       "      <td>365 (360)</td>\n",
       "      <td>5.52%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Hindi[a]</td>\n",
       "      <td>295 (310)</td>\n",
       "      <td>4.46%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>280 (295)</td>\n",
       "      <td>4.23%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>205 (215)</td>\n",
       "      <td>3.08%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Bengali</td>\n",
       "      <td>200 (205)</td>\n",
       "      <td>3.05%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Russian</td>\n",
       "      <td>160 (155)</td>\n",
       "      <td>2.42%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>125 (125)</td>\n",
       "      <td>1.92%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Punjabi</td>\n",
       "      <td>95 (100)</td>\n",
       "      <td>1.44%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank                  Language Native speakers Percentageof worldpopulation\n",
       "0    1  Mandarin (entire branch)       935 (955)                        14.1%\n",
       "1    2                   Spanish       390 (405)                        5.85%\n",
       "2    3                   English       365 (360)                        5.52%\n",
       "3    4                  Hindi[a]       295 (310)                        4.46%\n",
       "4    5                    Arabic       280 (295)                        4.23%\n",
       "5    6                Portuguese       205 (215)                        3.08%\n",
       "6    7                   Bengali       200 (205)                        3.05%\n",
       "7    8                   Russian       160 (155)                        2.42%\n",
       "8    9                  Japanese       125 (125)                        1.92%\n",
       "9   10                   Punjabi        95 (100)                        1.44%"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html12 = requests.get(url12).content\n",
    "\n",
    "soup12 = BeautifulSoup(html12, \"html\")\n",
    "\n",
    "soup12_find = soup12.find_all(\"table\")\n",
    "\n",
    "rows = soup12.find_all('tr')\n",
    "rows = [row.text.strip().split(\"\\n\") for row in rows]\n",
    "\n",
    "colnames = [\"Rank\", \"Language\", \"Native speakers\", \"Percentageof worldpopulation\"]\n",
    "\n",
    "data = rows[95:195]\n",
    "\n",
    "\n",
    "df_languages = pd.DataFrame(data, columns=colnames)\n",
    "df_languages.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "#### Scrape a certain number of tweets of a given Twitter account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display IMDB's top 250 data (movie name, initial release, director name and stars) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "url13 = 'https://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie name</th>\n",
       "      <th>initial release</th>\n",
       "      <th>director name and stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Les Évadés</td>\n",
       "      <td>(1994)</td>\n",
       "      <td>Frank Darabont (dir.), Tim Robbins, Morgan Fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Le parrain</td>\n",
       "      <td>(1972)</td>\n",
       "      <td>Francis Ford Coppola (dir.), Marlon Brando, Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Le parrain, 2ème partie</td>\n",
       "      <td>(1974)</td>\n",
       "      <td>Francis Ford Coppola (dir.), Al Pacino, Robert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight : Le Chevalier noir</td>\n",
       "      <td>(2008)</td>\n",
       "      <td>Christopher Nolan (dir.), Christian Bale, Heat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 hommes en colère</td>\n",
       "      <td>(1957)</td>\n",
       "      <td>Sidney Lumet (dir.), Henry Fonda, Lee J. Cobb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>La liste de Schindler</td>\n",
       "      <td>(1993)</td>\n",
       "      <td>Steven Spielberg (dir.), Liam Neeson, Ralph Fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Le Seigneur des anneaux : Le Retour du roi</td>\n",
       "      <td>(2003)</td>\n",
       "      <td>Peter Jackson (dir.), Elijah Wood, Viggo Morte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>(1994)</td>\n",
       "      <td>Quentin Tarantino (dir.), John Travolta, Uma T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Le Bon, la brute, le truand</td>\n",
       "      <td>(1966)</td>\n",
       "      <td>Sergio Leone (dir.), Clint Eastwood, Eli Wallach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Le Seigneur des anneaux : La Communauté de l'a...</td>\n",
       "      <td>(2001)</td>\n",
       "      <td>Peter Jackson (dir.), Elijah Wood, Ian McKellen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          movie name initial release  \\\n",
       "0                                         Les Évadés          (1994)   \n",
       "1                                         Le parrain          (1972)   \n",
       "2                            Le parrain, 2ème partie          (1974)   \n",
       "3                The Dark Knight : Le Chevalier noir          (2008)   \n",
       "4                                12 hommes en colère          (1957)   \n",
       "5                              La liste de Schindler          (1993)   \n",
       "6         Le Seigneur des anneaux : Le Retour du roi          (2003)   \n",
       "7                                       Pulp Fiction          (1994)   \n",
       "8                        Le Bon, la brute, le truand          (1966)   \n",
       "9  Le Seigneur des anneaux : La Communauté de l'a...          (2001)   \n",
       "\n",
       "                             director name and stars  \n",
       "0  Frank Darabont (dir.), Tim Robbins, Morgan Fre...  \n",
       "1  Francis Ford Coppola (dir.), Marlon Brando, Al...  \n",
       "2  Francis Ford Coppola (dir.), Al Pacino, Robert...  \n",
       "3  Christopher Nolan (dir.), Christian Bale, Heat...  \n",
       "4      Sidney Lumet (dir.), Henry Fonda, Lee J. Cobb  \n",
       "5  Steven Spielberg (dir.), Liam Neeson, Ralph Fi...  \n",
       "6  Peter Jackson (dir.), Elijah Wood, Viggo Morte...  \n",
       "7  Quentin Tarantino (dir.), John Travolta, Uma T...  \n",
       "8   Sergio Leone (dir.), Clint Eastwood, Eli Wallach  \n",
       "9    Peter Jackson (dir.), Elijah Wood, Ian McKellen  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html13 = requests.get(url13).content\n",
    "soup13 = BeautifulSoup(html13, \"html\")\n",
    "\n",
    "soup13_find = soup13.find_all(\"td\", {\"class\":\"titleColumn\"})\n",
    "\n",
    "rows = [[row.a.text]+[row.span.text]+[row.a['title']] for row in soup13_find]\n",
    "\n",
    "colnames = [\"movie name\", \"initial release\", \"director name and stars\"]\n",
    "\n",
    "data = rows\n",
    "\n",
    "df_languages = pd.DataFrame(data, columns=colnames)\n",
    "df_languages.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the movie name, year and a brief summary of the top 10 random movies (IMDB) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the url you will scrape in this exercise\n",
    "url13 = 'http://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_film = [row.a.get('href') for row in soup13_find]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Release</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gran Torino</td>\n",
       "      <td>2008</td>\n",
       "      <td>Disgruntled Korean War veteran Walt Kowalski s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apocalypse Now</td>\n",
       "      <td>1979</td>\n",
       "      <td>A U.S. Army officer serving in Vietnam is task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Le Fabuleux Destin d'Amélie Poulain</td>\n",
       "      <td>2001</td>\n",
       "      <td>Amélie is an innocent and naive girl in Paris ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avengers: Infinity War</td>\n",
       "      <td>2018</td>\n",
       "      <td>The Avengers and their allies must be willing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La mort aux trousses</td>\n",
       "      <td>1959</td>\n",
       "      <td>A New York City advertising executive goes on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Voyage à Tokyo</td>\n",
       "      <td>1953</td>\n",
       "      <td>An old couple visit their children and grandch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Reservoir Dogs</td>\n",
       "      <td>1992</td>\n",
       "      <td>When a simple jewelry heist goes horribly wron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1917</td>\n",
       "      <td>2019</td>\n",
       "      <td>April 6th, 1917. As a regiment assembles to wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Le Silence des agneaux</td>\n",
       "      <td>1991</td>\n",
       "      <td>A young F.B.I. cadet must receive the help of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Stalker</td>\n",
       "      <td>1979</td>\n",
       "      <td>A guide leads two men through an area known as...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title Release  \\\n",
       "0                          Gran Torino    2008   \n",
       "1                       Apocalypse Now    1979   \n",
       "2  Le Fabuleux Destin d'Amélie Poulain    2001   \n",
       "3               Avengers: Infinity War    2018   \n",
       "4                 La mort aux trousses    1959   \n",
       "5                       Voyage à Tokyo    1953   \n",
       "6                       Reservoir Dogs    1992   \n",
       "7                                 1917    2019   \n",
       "8               Le Silence des agneaux    1991   \n",
       "9                              Stalker    1979   \n",
       "\n",
       "                                             Summary  \n",
       "0  Disgruntled Korean War veteran Walt Kowalski s...  \n",
       "1  A U.S. Army officer serving in Vietnam is task...  \n",
       "2  Amélie is an innocent and naive girl in Paris ...  \n",
       "3  The Avengers and their allies must be willing ...  \n",
       "4  A New York City advertising executive goes on ...  \n",
       "5  An old couple visit their children and grandch...  \n",
       "6  When a simple jewelry heist goes horribly wron...  \n",
       "7  April 6th, 1917. As a regiment assembles to wa...  \n",
       "8  A young F.B.I. cadet must receive the help of ...  \n",
       "9  A guide leads two men through an area known as...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import shuffle;\n",
    "\n",
    "n_random = 10;\n",
    "\n",
    "html = requests.get(url13).content;\n",
    "soup = BeautifulSoup(html, \"lxml\");\n",
    "movies = soup.find_all('td', {'class':'titleColumn'})\n",
    "\n",
    "shuffle(movies)\n",
    "\n",
    "titles = [movie.find('a').text for movie in movies[0:n_random]]\n",
    "years = [movie.find('span').text[1:-1] for movie in movies[0:n_random]]\n",
    "links_to_movies = [movie.find('a').get('href') for movie in movies[0:n_random]]\n",
    "\n",
    "summary = []\n",
    "for link in links_to_movies:\n",
    "    html = requests.get('https://www.imdb.com' + link).content;\n",
    "    soup = BeautifulSoup(html, \"lxml\");\n",
    "    summary.append(soup.find('div', {'class':'summary_text'}).text.strip());\n",
    "\n",
    "movies_dict = {'Title': titles, 'Release': years, 'Summary': summary}\n",
    "\n",
    "movies_df = pd.DataFrame(movies_dict)\n",
    "movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the live weather report (temperature, wind speed, description and weather) of a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the city:  Orléans\n"
     ]
    }
   ],
   "source": [
    "#https://openweathermap.org/current\n",
    "city = input('Enter the city: ')\n",
    "url50 = 'http://api.openweathermap.org/data/2.5/weather?'+'q='+city+'&APPID=b35975e18dc93725acb092f7272cc6b8&units=metric'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coord': {'lon': 1.9039, 'lat': 47.9029},\n",
       " 'weather': [{'id': 801,\n",
       "   'main': 'Clouds',\n",
       "   'description': 'few clouds',\n",
       "   'icon': '02d'}],\n",
       " 'base': 'stations',\n",
       " 'main': {'temp': 11.98,\n",
       "  'feels_like': 10.36,\n",
       "  'temp_min': 11,\n",
       "  'temp_max': 13.33,\n",
       "  'pressure': 1024,\n",
       "  'humidity': 43},\n",
       " 'visibility': 10000,\n",
       " 'wind': {'speed': 8.75, 'deg': 30},\n",
       " 'clouds': {'all': 20},\n",
       " 'dt': 1617460620,\n",
       " 'sys': {'type': 1,\n",
       "  'id': 6534,\n",
       "  'country': 'FR',\n",
       "  'sunrise': 1617427588,\n",
       "  'sunset': 1617474265},\n",
       " 'timezone': 7200,\n",
       " 'id': 2989317,\n",
       " 'name': 'Orléans',\n",
       " 'cod': 200}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json \n",
    "response = requests.get(url50)\n",
    "results = response.json()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the book name, price and stock availability as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A Light in the Attic £51.77 In stock',\n",
       " 'Tipping the Velvet £51.77 In stock',\n",
       " 'Soumission £51.77 In stock',\n",
       " 'Sharp Objects £51.77 In stock',\n",
       " 'Sapiens: A Brief History of Humankind £51.77 In stock',\n",
       " 'The Requiem Red £51.77 In stock',\n",
       " 'The Dirty Little Secrets of Getting Your Dream Job £51.77 In stock',\n",
       " 'The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull £51.77 In stock',\n",
       " 'The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics £51.77 In stock',\n",
       " 'The Black Maria £51.77 In stock',\n",
       " 'Starving Hearts (Triangular Trade Trilogy, #1) £51.77 In stock',\n",
       " \"Shakespeare's Sonnets £51.77 In stock\",\n",
       " 'Set Me Free £51.77 In stock',\n",
       " \"Scott Pilgrim's Precious Little Life (Scott Pilgrim #1) £51.77 In stock\",\n",
       " 'Rip it Up and Start Again £51.77 In stock',\n",
       " 'Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991 £51.77 In stock',\n",
       " 'Olio £51.77 In stock',\n",
       " 'Mesaerion: The Best Science Fiction Stories 1800-1849 £51.77 In stock',\n",
       " 'Libertarianism for Beginners £51.77 In stock',\n",
       " \"It's Only the Himalayas £51.77 In stock\"]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the url you will scrape in this exercise. \n",
    "# It is a fictional bookstore created to be scraped. \n",
    "url51 = 'http://books.toscrape.com/'\n",
    "html51 = requests.get(url51).content\n",
    "soup51 = BeautifulSoup(html51, \"html\")\n",
    "\n",
    "soup51_find = soup51.find_all(\"article\",{\"class\",\"product_pod\"})\n",
    "\n",
    "div_prodprice = soup51.find('div', {'class': 'product_price'})\n",
    "\n",
    "price = div_prodprice.find_all('p')[0].text\n",
    "\n",
    "stock = div_prodprice.find_all('p')[1].text.strip()\n",
    "\n",
    "rows5 = [book.h3.a['title']+\" \"+price+\" \"+stock for book in soup51_find]\n",
    "rows5\n",
    "#soup51_find\n",
    "\n",
    "#colnames = [\"movie name\", \"initial release\", \"director name and stars\"]\n",
    "\n",
    "#data = rows\n",
    "\n",
    "#df_languages = pd.DataFrame(data, columns=colnames)\n",
    "#df_languages.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
