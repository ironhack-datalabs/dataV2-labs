{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferential statistics\n",
    "## Part III - Inferential Analysis\n",
    "\n",
    "We're now going to look for answers to the ongoing basketball discussions between you and your family. The main ones we want to reasearch are the following:\n",
    "\n",
    "- Your grandmother says that your sister couldn't play in a professional basketball league (not only the WNBA, but ANY professional basketball league) because she's too skinny and lacks muscle.\n",
    "- Your sister says that most female professional players fail their free throws.\n",
    "- Your brother-in-law heard on the TV that the average assists among NBA (male) and WNBA (female) players is 52 for the 2016-2017 season. He is convinced this average would be higher if we only considered the players from the WNBA.\n",
    "\n",
    "Let's investigate these claims and see if we can find proof to refute or support them.\n",
    "\n",
    "### Libraries\n",
    "Import the necessary libraries first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_1samp\n",
    "pd.set_option('max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n",
    "\n",
    "Load the cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Birth_Place</th>\n",
       "      <th>Birthdate</th>\n",
       "      <th>Age</th>\n",
       "      <th>College</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Games Played</th>\n",
       "      <th>MIN</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3PM</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TO</th>\n",
       "      <th>PTS</th>\n",
       "      <th>DD2</th>\n",
       "      <th>TD3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aerial Powers</td>\n",
       "      <td>DAL</td>\n",
       "      <td>F</td>\n",
       "      <td>183</td>\n",
       "      <td>71</td>\n",
       "      <td>21.200991</td>\n",
       "      <td>US</td>\n",
       "      <td>January 17, 1994</td>\n",
       "      <td>23</td>\n",
       "      <td>Michigan State</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>173</td>\n",
       "      <td>30</td>\n",
       "      <td>85</td>\n",
       "      <td>35.3</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>37.5</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>80.8</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alana Beard</td>\n",
       "      <td>LA</td>\n",
       "      <td>G/F</td>\n",
       "      <td>185</td>\n",
       "      <td>73</td>\n",
       "      <td>21.329438</td>\n",
       "      <td>US</td>\n",
       "      <td>May 14, 1982</td>\n",
       "      <td>35</td>\n",
       "      <td>Duke</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>947</td>\n",
       "      <td>90</td>\n",
       "      <td>177</td>\n",
       "      <td>50.8</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>41</td>\n",
       "      <td>78.0</td>\n",
       "      <td>19</td>\n",
       "      <td>82</td>\n",
       "      <td>101</td>\n",
       "      <td>72</td>\n",
       "      <td>63</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alex Bentley</td>\n",
       "      <td>CON</td>\n",
       "      <td>G</td>\n",
       "      <td>170</td>\n",
       "      <td>69</td>\n",
       "      <td>23.875433</td>\n",
       "      <td>US</td>\n",
       "      <td>October 27, 1990</td>\n",
       "      <td>26</td>\n",
       "      <td>Penn State</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>617</td>\n",
       "      <td>82</td>\n",
       "      <td>218</td>\n",
       "      <td>37.6</td>\n",
       "      <td>19</td>\n",
       "      <td>64</td>\n",
       "      <td>29.7</td>\n",
       "      <td>35</td>\n",
       "      <td>42</td>\n",
       "      <td>83.3</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>78</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alex Montgomery</td>\n",
       "      <td>SAN</td>\n",
       "      <td>G/F</td>\n",
       "      <td>185</td>\n",
       "      <td>84</td>\n",
       "      <td>24.543462</td>\n",
       "      <td>US</td>\n",
       "      <td>December 11, 1988</td>\n",
       "      <td>28</td>\n",
       "      <td>Georgia Tech</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>721</td>\n",
       "      <td>75</td>\n",
       "      <td>195</td>\n",
       "      <td>38.5</td>\n",
       "      <td>21</td>\n",
       "      <td>68</td>\n",
       "      <td>30.9</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>81.0</td>\n",
       "      <td>35</td>\n",
       "      <td>134</td>\n",
       "      <td>169</td>\n",
       "      <td>65</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alexis Jones</td>\n",
       "      <td>MIN</td>\n",
       "      <td>G</td>\n",
       "      <td>175</td>\n",
       "      <td>78</td>\n",
       "      <td>25.469388</td>\n",
       "      <td>US</td>\n",
       "      <td>August 5, 1994</td>\n",
       "      <td>23</td>\n",
       "      <td>Baylor</td>\n",
       "      <td>R</td>\n",
       "      <td>24</td>\n",
       "      <td>137</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>35.0</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>91.7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name Team  Pos  Height  Weight        BMI Birth_Place  \\\n",
       "0    Aerial Powers  DAL    F     183      71  21.200991          US   \n",
       "1      Alana Beard   LA  G/F     185      73  21.329438          US   \n",
       "2     Alex Bentley  CON    G     170      69  23.875433          US   \n",
       "3  Alex Montgomery  SAN  G/F     185      84  24.543462          US   \n",
       "4     Alexis Jones  MIN    G     175      78  25.469388          US   \n",
       "\n",
       "           Birthdate  Age         College Experience  Games Played  MIN  FGM  \\\n",
       "0   January 17, 1994   23  Michigan State          2             8  173   30   \n",
       "1       May 14, 1982   35            Duke         12            30  947   90   \n",
       "2   October 27, 1990   26      Penn State          4            26  617   82   \n",
       "3  December 11, 1988   28    Georgia Tech          6            31  721   75   \n",
       "4     August 5, 1994   23          Baylor          R            24  137   16   \n",
       "\n",
       "   FGA   FG%  3PM  3PA   3P%  FTM  FTA   FT%  OREB  DREB  REB  AST  STL  BLK  \\\n",
       "0   85  35.3   12   32  37.5   21   26  80.8     6    22   28   12    3    6   \n",
       "1  177  50.8    5   18  27.8   32   41  78.0    19    82  101   72   63   13   \n",
       "2  218  37.6   19   64  29.7   35   42  83.3     4    36   40   78   22    3   \n",
       "3  195  38.5   21   68  30.9   17   21  81.0    35   134  169   65   20   10   \n",
       "4   50  32.0    7   20  35.0   11   12  91.7     3     9   12   12    7    0   \n",
       "\n",
       "   TO  PTS  DD2  TD3  \n",
       "0  12   93    0    0  \n",
       "1  40  217    0    0  \n",
       "2  24  218    0    0  \n",
       "3  38  188    2    0  \n",
       "4  14   50    0    0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnba = pd.read_csv('../data/wnba_clean.csv')\n",
    "wnba.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Can my sister play in a professional female basketball league?\n",
    "\n",
    "As we said, you grandmother is convinced that your sister couldn't play in a professional league because of her physique and weight (her weight is 67kg). \n",
    "\n",
    "To find an actual answer to the question we first need to know what's the average weight of a professional female basketball player. The data we have only refers to the WNBA league and not to every female professional basketball league in the world, therefore we have no way of actually calculating it.\n",
    "\n",
    "Still, given that we do have *some* data we can **infer** it using a sample of players like the one we have. \n",
    "\n",
    "**How would you do it? Try and think about the requirements that your sample must satisfy in order to be used to infer the average weight. Do you feel it actually fulfills those requirements? Do you need to make any assumptions? We could calculate a confidence interval to do the inference, but do you know any other ways?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to find sample mean and sample standard deviation and then calculate conference intervals using 95% confidence level.\n",
    "#Our sample has to be a representative sample of the entire population\n",
    "#Our assumption is that weight is normally distributed. \n",
    "#There is no other way to calculate average weight expect with the sample we are given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that all the requirements have been taken into account, compute the confidence interval of the average weight with a confidence level of 95%.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.97887323943662\n",
      "10.957323301868858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(57.50291420081216, 100.45483227806109)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_weight = np.mean(wnba['Weight'])\n",
    "print(mean_weight)\n",
    "std_weight = np.std(wnba[\"Weight\"])\n",
    "print(std_weight)\n",
    "\n",
    "lower, upper = stats.norm.interval(0.95, loc=mean_weight, scale=std_weight)\n",
    "lower, upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What can you say about these results?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.07042253521126"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#there is a 95% confidence that a random player will weight between 57.51 and 100.45kgs\n",
    "len(wnba[(wnba[\"Weight\"]>= lower) & (wnba[\"Weight\"]<=upper)])/len(wnba)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If your sister weighs 67kg what would you tell your grandmother in regards to her assumption?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.97887323943662\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(wnba['Weight']))\n",
    "#her weight of 67kg falls within confidence intervals of 57.51 and 100.45kgs\n",
    "#which accounts for 95% of all players weight, so she could definitely play in WNBA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Can you plot the probability distribution of the average weight, indicating where the critical region is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Do female professional basketball players fail the majority of their free throws?\n",
    "\n",
    "You do not agree with your sister when she says that most female players fail their free throws. You decide to try and estimate the percentage of players that fail more than 40% of their free throws using, you guessed it, the WNBA sample.\n",
    "\n",
    "**How would you do it? Try and think about the requirements that your sample must satisfy in order to be used to infer the proportion of players that miss more than 40% of their free throws. Do you feel it actually fulfills those requirements? Do you need to make any assumptions?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that all the requirements have been taken into account, compute the confidence interval of the proportion with a confidence level of 95%:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>80.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>41</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>42</td>\n",
       "      <td>83.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>91.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>136</td>\n",
       "      <td>161</td>\n",
       "      <td>84.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>66.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>94</td>\n",
       "      <td>102</td>\n",
       "      <td>92.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>110</td>\n",
       "      <td>135</td>\n",
       "      <td>81.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>78.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FTM  FTA   FT%\n",
       "0     21   26  80.8\n",
       "1     32   41  78.0\n",
       "2     35   42  83.3\n",
       "3     17   21  81.0\n",
       "4     11   12  91.7\n",
       "..   ...  ...   ...\n",
       "137  136  161  84.5\n",
       "138    4    6  66.7\n",
       "139   94  102  92.2\n",
       "140  110  135  81.5\n",
       "141   22   28  78.6\n",
       "\n",
       "[142 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FTM = Free Throws made\n",
    "#FTA = Free Throws Attempts\n",
    "#FT% = Free Throws % \n",
    "\n",
    "free_throws = wnba[['FTM', 'FTA', 'FT%']]\n",
    "free_throws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09859154929577464\n",
      "0.025017072438697795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0982462495705741, 0.09893684902097519)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc = wnba['FT%'].mean()\n",
    "scale = wnba['FT%'].std()\n",
    "\n",
    "p_count = len(wnba)\n",
    "pm_count = len(wnba[wnba['FT%']<60])\n",
    "prop = pm_count/p_count\n",
    "print(prop)\n",
    "std = ((prop*(1-prop))/p_count)**0.5\n",
    "print(std)\n",
    "\n",
    "upper, lower = stats.norm.interval(0.95, loc=prop, scale=std/p_count)\n",
    "upper, lower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What can you comment about our result? What would you tell your sister?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your-answer-here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Can you plot the probability distribution of the proportion of missed free throws, indicating where the critical region is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Is the average number of assists for WNBA players only higher than the average for WNBA and NBA players together?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your brother-in-law is convinced that the average assists for female professional players is higher than the average of both female and male players combined (which is 52 for the 2016-2017 season). You would like to actually prove if this is true or not but you remember your stats teacher saying \"you can't *prove* anything, you just can say that *you are not* saying foolishness\".\n",
    "\n",
    "**How would you do it? Try and think about the requirements that your sample must satisfy in order to do that. Do you feel it actually fulfills those requirements? Do you need to make any assumptions?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your-answer-here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use a two-tailed one-sample t-test to see if we can reject (or not) the null hypothesis with a 95% confidence level.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=-2.1499947192482898, pvalue=0.033261541354107166)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#two-tailed one-sample t-test at 95% confidence level\n",
    "#H0: they are the same or less\n",
    "#H1: there is difference between average assists for female vs both female and male players\n",
    "#We reject the null hypothesis\n",
    "\n",
    "ttest_1samp(wnba['AST'], 52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your-answer-here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now use a one-tailed one-sample t-test to see if we can reject (or not) the null hypothesis with a 95% confidence level.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=-2.1499947192482898, pvalue=0.033261541354107166)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in a one-tailed test you divide p-value by two\n",
    "ttest_1samp(wnba['AST'], 52)\n",
    "#We reject the null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Can you plot the resulting t-distribution of both tests? Indicate where the is the critical region and where does your statistic fall.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Satisfying your curiosity\n",
    "\n",
    "You finally managed to solve your family's debates over basketball! While you were doing that you started to take an interest in the normal distribution.\n",
    "\n",
    "You read that the normal distribution is present in a lot of natural phenomenons, like blood pressure, IQ, weight and height. If, for example, we could plot the distribution of the weights of every human on the planet right now it would have the shape of a normal distribution.\n",
    "\n",
    "In light of this you would like to see if it's possible to check if the distribution of the weights of the WNBA players is a sample distribution that comes from a population that has a normal distribution, because theoretically this should be the case.\n",
    "\n",
    "**How would you try to demonstrate that our sample fits a normal distribution? What kind of test would you use? Would you have to make any assumptions?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your-answer-here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What are your comments in regards to the results of the test?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your-answer-here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
